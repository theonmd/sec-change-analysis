{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "89bf1b53d9804adbb4084507d2a6dc49",
    "deepnote_cell_height": 134,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Final analysis of large cap companies and first results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "c386c714-1adc-47ae-8a67-33463b7cfe8d",
    "deepnote_cell_height": 225,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     289.8125
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 150,
    "execution_start": 1651081946596,
    "source_hash": "90ef6991",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: w3lib in /Users/theolanganay/opt/anaconda3/lib/python3.9/site-packages (1.22.0)\n",
      "Requirement already satisfied: six>=1.4.1 in /Users/theolanganay/opt/anaconda3/lib/python3.9/site-packages (from w3lib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U sec-edgar-downloader | grep -v 'already satisfied' \n",
    "%pip install yfinance | grep -v 'already satisfied'\n",
    "%pip install pandas_datareader | grep -v 'already satisfied' \n",
    "%pip install cleantext | grep -v 'already satisfied'\n",
    "%pip install ipynb | grep -v 'already satisfied'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ipynb\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "%run A_data_extraction.ipynb\n",
    "%run I_data_pre_processing.ipynb\n",
    "%run II_models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparisons(tkrs, n, plot = False):\n",
    "    '''\n",
    "    Function that takes as input a list of tickers and a number of years to perform the comparison on\n",
    "    Performs comparisons for all companies in the list and saves the scores as a pickle file\n",
    "    '''\n",
    "    sim_dic = {}\n",
    "    for tick in tkrs:\n",
    "        print('Working on {}'.format(tick))\n",
    "        # Download raw files and create folders for each company (A_data_extraction.ipynb)\n",
    "        files_downloader(\"10-K\", str(tick), n = n)\n",
    "        \n",
    "        # Clean the previously downloaded files and store them in the clean folder (I_data_pre_processing.ipynb)\n",
    "        # Create the compnay object\n",
    "        comp_files = files_cleaning(tick)\n",
    "        # Create the clean files\n",
    "        comp_files.write_clean_files()\n",
    "        \n",
    "        # Compute similarities (II_models.ipynb)\n",
    "        print('Computing similarities...')\n",
    "        comp_sim = similarities(tick)\n",
    "        comp_df = comp_sim.compute_sim('01', 'tfidf')\n",
    "        sim_dic[tick] = comp_df\n",
    "        \n",
    "        if plot:\n",
    "            sns.kdeplot(data = comp_sim, x = 'tfidf_cosine_sim')\n",
    "            plt.show()\n",
    "            \n",
    "        \n",
    "        # Save the company's similarities\n",
    "        save_path = './data/{}/{}_similarities.pickle'.format(tick, tick)\n",
    "        with open(save_path, 'wb') as handle:\n",
    "            pickle.dump(comp_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "        print('Done with {}!'.format(tick))\n",
    "        print('--------------------------')\n",
    "    \n",
    "    # Save the similarities as pickle file\n",
    "    save_path = './data/similarities.pickle'\n",
    "    with open(save_path, 'wb') as handle:\n",
    "        pickle.dump(sim_dic, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_all():\n",
    "    '''\n",
    "    Function that removes all files to rerun next step\n",
    "    '''\n",
    "    for tick in os.listdir('./data'):\n",
    "        clean_path = os.path.join('./data', tick, 'clean')\n",
    "        raw_path = os.path.join('./data', tick, 'raw')\n",
    "        \n",
    "        if os.path.exists(raw_path):\n",
    "            for f in os.listdir(raw_path):\n",
    "                if not f[0] == '.':\n",
    "                    os.remove(os.path.join(raw_path, f))  \n",
    "\n",
    "        if os.path.exists(clean_path):\n",
    "            for f in os.listdir(clean_path):\n",
    "                if not f[0] == '.':\n",
    "                    os.remove(os.path.join(clean_path, f))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "b245c12e5da54e57a4b0354786c7e477",
    "deepnote_cell_height": 99,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8,
    "execution_start": 1651082056991,
    "source_hash": "affbd58e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tickers_df = pd.read_csv('./data/stock_tickers.csv', sep = ';')[['ticker']]\n",
    "tickers = list(tickers_df.ticker.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on MSFT\n",
      "Extracting textual content...\n",
      "Cleaning the text (might take long)...\n",
      "Writing the clean files...\n",
      "Computing similarities...\n",
      "Done with MSFT!\n",
      "--------------------------\n",
      "Working on GOOG\n",
      "Extracting textual content...\n",
      "Cleaning the text (might take long)...\n",
      "Writing the clean files...\n",
      "Computing similarities...\n",
      "Done with GOOG!\n",
      "--------------------------\n",
      "Working on TSLA\n",
      "Extracting textual content...\n",
      "Cleaning the text (might take long)...\n",
      "Writing the clean files...\n",
      "Computing similarities...\n",
      "Done with TSLA!\n",
      "--------------------------\n",
      "Working on UNH\n",
      "Extracting textual content...\n",
      "Cleaning the text (might take long)...\n",
      "Writing the clean files...\n",
      "Computing similarities...\n",
      "Done with UNH!\n",
      "--------------------------\n",
      "Working on JNJ\n",
      "Extracting textual content...\n",
      "Cleaning the text (might take long)...\n",
      "Writing the clean files...\n",
      "Computing similarities...\n",
      "Done with JNJ!\n",
      "--------------------------\n",
      "Working on FB\n",
      "Extracting textual content...\n",
      "Cleaning the text (might take long)...\n",
      "Writing the clean files...\n",
      "Computing similarities...\n",
      "Done with FB!\n",
      "--------------------------\n",
      "Working on NVDA\n",
      "Extracting textual content...\n",
      "Cleaning the text (might take long)...\n",
      "Writing the clean files...\n",
      "Computing similarities...\n",
      "Done with NVDA!\n",
      "--------------------------\n",
      "Working on V\n",
      "Extracting textual content...\n",
      "Cleaning the text (might take long)...\n",
      "Writing the clean files...\n",
      "Computing similarities...\n",
      "Done with V!\n",
      "--------------------------\n",
      "Working on WMT\n",
      "Extracting textual content...\n",
      "Cleaning the text (might take long)...\n",
      "Writing the clean files...\n",
      "Computing similarities...\n",
      "Done with WMT!\n",
      "--------------------------\n",
      "Working on PG\n",
      "Extracting textual content...\n",
      "Cleaning the text (might take long)...\n",
      "Writing the clean files...\n",
      "Computing similarities...\n",
      "Done with PG!\n",
      "--------------------------\n",
      "Working on JPM\n",
      "Extracting textual content...\n",
      "Cleaning the text (might take long)...\n",
      "Writing the clean files...\n",
      "Computing similarities...\n",
      "Done with JPM!\n",
      "--------------------------\n",
      "Working on XOM\n"
     ]
    }
   ],
   "source": [
    "comparisons(tickers[1:60], n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [
   {
    "cellId": "8971303d020c4fc6b53541ba0cf5f7da",
    "msgId": "25257176-0092-4c70-b080-a8431affeca5",
    "sessionId": "134ce00c-aff5-4af9-931e-acda8cf07376"
   }
  ],
  "deepnote_notebook_id": "0e2e84f0-027d-426e-9182-5bcc6f578bd8",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
