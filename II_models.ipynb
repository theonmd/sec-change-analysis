{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "ed470784-5f26-47bb-b58a-3b800996afec",
    "deepnote_cell_height": 297,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1880,
    "execution_start": 1649723583920,
    "source_hash": "ef4912fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from functools import reduce\n",
    "\n",
    "# Machine learning packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a3df156f-8739-423c-a5ef-72dc09cbf3cd",
    "deepnote_cell_height": 62,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Create a class that performs cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "9bddca41-350c-4c10-9e0c-f50059845e98",
    "deepnote_cell_height": 4941,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 182,
    "execution_start": 1649723585809,
    "source_hash": "57a6620b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class similarities():\n",
    "    '''\n",
    "    Class that performs the different similarities between clean files of a given company\n",
    "    Cosine similarity on DTF / Cosine similarity on TF-IDF / Jaccard Similarity...\n",
    "    '''\n",
    "    def __init__(self, comp_code):\n",
    "        self.comp_code = comp_code\n",
    "\n",
    "\n",
    "    def shape_data(self):\n",
    "        '''\n",
    "        Returns the company's clean data in a dictionnary shape\n",
    "        '''\n",
    "        comp_clean_path = './data/{}/clean/'.format(self.comp_code)\n",
    "        comp_data_dic = {}\n",
    "\n",
    "        if not os.path.isdir(comp_clean_path):\n",
    "            raise Exception(\"Company's clean files don't exist: check folder!\")\n",
    "\n",
    "        for f in os.listdir(comp_clean_path):\n",
    "            # If the file is not a company file\n",
    "            if f[0] == '.':\n",
    "                continue\n",
    "            \n",
    "            # Extract the year\n",
    "            year = int(f.split('_')[1])\n",
    "\n",
    "            f_path = os.path.join(comp_clean_path, f)\n",
    "            f_txt = open(f_path, \"r\")\n",
    "            f_str = f_txt.read()\n",
    "\n",
    "            # Add the string to the company's list\n",
    "            comp_data_dic[year] = f_str\n",
    "\n",
    "            # Close the file\n",
    "            f_txt.close()\n",
    "\n",
    "        return(comp_data_dic)\n",
    "\n",
    "    \n",
    "    def match_years(self, year):\n",
    "        '''\n",
    "        Function that takes as input the starting interesting year\n",
    "        Returns a list of tuples with years to match: [(year_1, year_2), (year_2, year_3), ...]\n",
    "        '''\n",
    "        comp_clean_path = './data/{}/clean/'.format(self.comp_code)\n",
    "        comp_data_dic = {}\n",
    "        years = []\n",
    "\n",
    "        for f in os.listdir(comp_clean_path):\n",
    "            # If the file is not a company file \n",
    "            if f[0] == '.':\n",
    "                continue\n",
    "            # Extract the year\n",
    "            year_doc = f.split('_')[1]\n",
    "            years.append(int(year_doc))\n",
    "        \n",
    "        comp_years = sorted([y for y in years if y >= int(year)])\n",
    "        \n",
    "        # If there are no years to match\n",
    "        if len(comp_years) == 0 or len(comp_years) == 1:\n",
    "            return([])\n",
    "\n",
    "        match_years = []\n",
    "        for i in range(len(comp_years[:-1])):\n",
    "            match_years.append((comp_years[i], comp_years[i+1]))\n",
    "        \n",
    "        return(match_years)\n",
    "\n",
    "\n",
    "\n",
    "    def jaccard(self, year): \n",
    "        '''\n",
    "        Simple implementation of the Jaccard similarity (intersection / union of two texts)\n",
    "        '''\n",
    "        # Extract the company's data from the folder\n",
    "        comp_data_dic = self.shape_data()\n",
    "        year = int(year)\n",
    "\n",
    "#         if year not in list(comp_data_dic.keys()):\n",
    "#             raise Exception('Year not in folder! Check folder or check year format (YY)')\n",
    "\n",
    "        # Years to match\n",
    "        match = self.match_years(year)\n",
    "        \n",
    "        if len(match) == 0:\n",
    "            return(pd.DataFrame({'year_1':[], 'year_2':[], 'jaccard_sim':[]}))\n",
    "\n",
    "        # Loop over the other texts and find the similarities\n",
    "        jaccard_sim = []\n",
    "        year1, year2 = [], []\n",
    "\n",
    "        for y1, y2 in match:\n",
    "            # Extract the text for both years\n",
    "            text1, text2 = comp_data_dic[y1], comp_data_dic[y2]\n",
    "\n",
    "            # List the unique words in a document\n",
    "            words1 = set(text1.split()) \n",
    "            words2 = set(text2.split())\n",
    "            \n",
    "            # Find the intersection of words list of doc1 & doc2\n",
    "            intersection = words1.intersection(words2)\n",
    "\n",
    "            # Find the union of words list of doc1 & doc2\n",
    "            union = words1.union(words2)\n",
    "            \n",
    "            # Add the Jaccard similarity to the list\n",
    "            jaccard_sim.append(float(len(intersection)) / len(union))\n",
    "\n",
    "            # Add years to the lists\n",
    "            year1.append(y1)\n",
    "            year2.append(y2)\n",
    "\n",
    "        # Turn the results into a dataframe\n",
    "        final_df = pd.DataFrame({'year_1': year1, 'year_2': year2, 'jaccard_sim': [np.round(jac, 3) for jac in jaccard_sim]})\n",
    "\n",
    "        return(final_df)\n",
    "    \n",
    "\n",
    "    def dtf_cosine(self, year):\n",
    "        '''\n",
    "        Returns the dtf implementation of cosine similarity for the desired year with all the other years\n",
    "        '''\n",
    "        # Extract the company's data from the folder\n",
    "        comp_data_dic = self.shape_data()\n",
    "        year = int(year)\n",
    "\n",
    "        # Function that creates the full document \n",
    "        union = lambda t1, t2: set(t1.split()).union(set(t2.split()))\n",
    "\n",
    "        # Function that counts the number of occurences of words from text in the full document\n",
    "        def DTF(doc, text): \n",
    "            res = dict.fromkeys(doc,0)\n",
    "            for word in text.split():\n",
    "                res[word]+=1 \n",
    "            return res\n",
    "\n",
    "#         if year not in list(comp_data_dic.keys()):\n",
    "#             raise Exception('Year not in folder! Check folder or check year format (YY)')\n",
    "\n",
    "        # Years to match\n",
    "        match = self.match_years(year)\n",
    "        \n",
    "        if len(match) == 0:\n",
    "            return(pd.DataFrame({'year_1':[], 'year_2':[], 'dtf_cosine_sim':[]}))\n",
    "\n",
    "        # Loop over the other texts and find the cosine similarities\n",
    "        cosine_sim = []\n",
    "        year1, year2 = [], []\n",
    "\n",
    "        for y1, y2 in match:\n",
    "            # Extract the text for both years\n",
    "            text1, text2 = comp_data_dic[y1], comp_data_dic[y2]\n",
    "\n",
    "            full_text = union(text1, text2)\n",
    "            D1_TF = DTF(full_text, text1)\n",
    "            D2_TF = DTF(full_text, text2)\n",
    "            df = pd.DataFrame([D1_TF,D2_TF])\n",
    "            df1 = df.loc[0,:]\n",
    "            df2 = df.loc[1,:]\n",
    "            cosine_sim.append(np.dot(df1,df2)/(np.linalg.norm(df1)*np.linalg.norm(df2)))\n",
    "\n",
    "            # Add the years\n",
    "            year1.append(y1)\n",
    "            year2.append(y2)\n",
    "\n",
    "        # Turn the results into a dataframe\n",
    "        final_df = pd.DataFrame({'year_1': year1, 'year_2': year2, 'dtf_cosine_sim': [np.round(cos, 2) for cos in cosine_sim]})\n",
    "\n",
    "        return(final_df)\n",
    "\n",
    "\n",
    "\n",
    "    def tfidf_cosine(self, year):\n",
    "        '''\n",
    "        Returns the tf-idf implementation of cosine similarity for the desired year with all the other years\n",
    "        '''\n",
    "        # Extract the company's data from the folder\n",
    "        comp_data_dic = self.shape_data()\n",
    "        year = int(year)\n",
    "\n",
    "        # Get the matching years\n",
    "        match = self.match_years(year)\n",
    "        \n",
    "        if len(match) == 0:\n",
    "            return(pd.DataFrame({'year_1':[], 'year_2':[], 'tfidf_cosine_sim':[]}))\n",
    "            \n",
    "        \n",
    "        match_u = list(set([y1 for y in match for y1 in y]))\n",
    "\n",
    "        # Apply the tf-idf vectorization\n",
    "        tfidf_data = TfidfVectorizer().fit_transform([comp_data_dic[y] for y in match_u])\n",
    "\n",
    "        # Put this data in a dictionnary\n",
    "        comp_data_tfidf_dic = {year_doc: tfidf_data[i] for i, year_doc in enumerate(match_u)}\n",
    "                \n",
    "#         if year not in list(comp_data_dic.keys()):\n",
    "#             raise Exception('Year not in folder! Check folder or check year format (YY)')\n",
    "\n",
    "        cosine_sim = []\n",
    "        year1, year2 = [], []\n",
    "\n",
    "        for y1, y2 in match:\n",
    "            # Extract the text for both years\n",
    "            text1, text2 = comp_data_tfidf_dic[y1], comp_data_tfidf_dic[y2]\n",
    "\n",
    "            # Perform the cosine sim\n",
    "            cosine = linear_kernel(text1, text2).flatten()[0]\n",
    "\n",
    "            # Add everything to the results\n",
    "            cosine_sim.append(cosine)\n",
    "            year1.append(y1)\n",
    "            year2.append(y2)\n",
    "\n",
    "        # Turn the results into a DataFrame\n",
    "        final_df = pd.DataFrame({'year_1': year1, 'year_2': year2, 'tfidf_cosine_sim': [np.round(cos, 2) for cos in cosine_sim]})\n",
    "\n",
    "        return(final_df)\n",
    "            \n",
    "\n",
    "    def euclidian(self, year):\n",
    "        '''\n",
    "        Returns the euclidian distance with tf-idf vectorization for the desired year with all the other years\n",
    "        '''\n",
    "        # Extract the company's data from the folder\n",
    "        comp_data_dic = self.shape_data()\n",
    "        year = int(year)\n",
    "\n",
    "        # Get the matching years\n",
    "        match = self.match_years(year)\n",
    "        \n",
    "        if len(match) == 0:\n",
    "            return(pd.DataFrame({'year_1':[], 'year_2':[], 'euclidian_dist':[]}))\n",
    "        \n",
    "        match_u = list(set([y1 for y in match for y1 in y]))\n",
    "\n",
    "        # Apply the tf-idf vectorization\n",
    "        tfidf_data = TfidfVectorizer().fit_transform([comp_data_dic[y] for y in match_u])\n",
    "\n",
    "        # Put this data in a dictionnary\n",
    "        comp_data_tfidf_dic = {year_doc: tfidf_data[i] for i, year_doc in enumerate(match_u)}\n",
    "                \n",
    "#         if year not in list(comp_data_dic.keys()):\n",
    "#             raise Exception('Year not in folder! Check folder or check year format (YY)')\n",
    "\n",
    "        euc_dist = []\n",
    "        year1, year2 = [], []\n",
    "\n",
    "        for y1, y2 in match:\n",
    "            # Extract the text for both years\n",
    "            text1, text2 = comp_data_tfidf_dic[y1], comp_data_tfidf_dic[y2]\n",
    "\n",
    "            # Perform the cosine sim\n",
    "            euc = euclidean_distances(text1, text2).flatten()[0]\n",
    "\n",
    "            # Add everything to the results\n",
    "            euc_dist.append(euc)\n",
    "            year1.append(y1)\n",
    "            year2.append(y2)\n",
    "\n",
    "\n",
    "        # Turn the results into a DataFrame\n",
    "        final_df = pd.DataFrame({'year_1': year1, 'year_2': year2, 'euclidean_dist': [np.round(e, 2) for e in euc_dist]})\n",
    "\n",
    "        return(final_df)\n",
    "\n",
    "\n",
    "    def compute_sim(self, year, *sims):\n",
    "        '''\n",
    "        Function that takes as input similarities / distances to compute\n",
    "        Return a DataFrame with the results\n",
    "        '''\n",
    "        sim_match = {\n",
    "            'jaccard': lambda y: self.jaccard(y),\n",
    "            'dtf': lambda y: self.dtf_cosine(y),\n",
    "            'tfidf': lambda y: self.tfidf_cosine(y),\n",
    "            'euclidian': lambda y: self.euclidian(y)\n",
    "        }\n",
    "\n",
    "        df_list = []\n",
    "        for sim in sims:\n",
    "            if sim not in list(sim_match.keys()):\n",
    "                raise Exception('Check the similarities you ask for! Can only be in this list: [jaccard, dtf, tfidf, euclidian]')\n",
    "\n",
    "            df_list.append(sim_match[sim](year))\n",
    "\n",
    "        # Merge all the dfs together\n",
    "        final_df = reduce(lambda x, y: pd.merge(x, y, on = ['year_1', 'year_2']), df_list)\n",
    "\n",
    "        # Order the final df\n",
    "        final_df.year_1 = final_df.year_1.transform(int)\n",
    "        final_df.year_2 = final_df.year_2.transform(int)\n",
    "\n",
    "        return(final_df.sort_values(by = 'year_2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "8f13782d-6b84-445f-abb1-65512c0a85f1",
    "deepnote_cell_height": 133,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 346,
    "execution_start": 1649723586002,
    "source_hash": "90217497",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([18, 19, 11, 13, 12, 15, 17, 16, 21, 20])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Apple object\n",
    "# apple_sim = similarities('AAPL')\n",
    "# apple_sim.shape_data().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2f5a0e84-99d9-49b2-ba3a-81b1dff2669e",
    "deepnote_cell_height": 99,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 115354,
    "execution_start": 1649723586355,
    "owner_user_id": "84094537-d0b3-4bb4-8a57-76f1d8ff63d1",
    "source_hash": "59b3a6c5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the desired distances / similarities in a dataframe\n",
    "# apple_df = apple_sim.compute_sim(12, 'jaccard', 'dtf', 'tfidf', 'euclidian')"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "bb30377d-2fa4-416b-9e1a-72d084e3ecd0",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
